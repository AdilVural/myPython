{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792da492",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/deel2_pipeline.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m src_path = Path(\u001b[33m\"\u001b[39m\u001b[33m/mnt/data/deel2_pipeline.py\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src_path.exists():\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Schrijf een placeholder of jouw eigen pipeline code naar dit pad\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43msrc_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m# TODO: Voeg hier de code van deel2_pipeline.py toe\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdef main():\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m    print(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPipeline code ontbreekt. Voeg deze toe aan /mnt/data/deel2_pipeline.py\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmain()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m code = src_path.read_text(encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m code = code.replace(\u001b[33m'\u001b[39m\u001b[33mDATA_PATH = \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcollege_statistics.csv\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDATA_PATH = \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:555\u001b[39m, in \u001b[36mPath.write_text\u001b[39m\u001b[34m(self, data, encoding, errors, newline)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# Call io.text_encoding() here to ensure any warning is raised at an\u001b[39;00m\n\u001b[32m    553\u001b[39m \u001b[38;5;66;03m# appropriate stack level.\u001b[39;00m\n\u001b[32m    554\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPathBase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_abc.py:651\u001b[39m, in \u001b[36mPathBase.write_text\u001b[39m\u001b[34m(self, data, encoding, errors, newline)\u001b[39m\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    649\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mdata must be str, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m %\n\u001b[32m    650\u001b[39m                     data.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f.write(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:537\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    536\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/mnt/data/deel2_pipeline.py'"
     ]
    }
   ],
   "source": [
    "# === Deel 2 pipeline runner (Jupyter-safe, één cel) ===\n",
    "# Pas ALLEEN deze regel aan naar jouw CSV-bestand:\n",
    "DATA_PATH = \"college_statistics.csv\"   # <--- verander hier zo nodig\n",
    "\n",
    "# 1) (eenmalig) dependencies installeren – safe als het al bestaat\n",
    "try:\n",
    "    import pandas, numpy, scipy, statsmodels, sklearn, matplotlib, patsy  # noqa: F401\n",
    "except Exception:\n",
    "    %pip install pandas numpy scipy statsmodels scikit-learn matplotlib patsy\n",
    "\n",
    "# 2) Lees het reeds aangemaakte script en vervang alleen de DATA_PATH-regel\n",
    "from pathlib import Path\n",
    "src_path = Path(\"/mnt/data/deel2_pipeline.py\")\n",
    "if not src_path.exists():\n",
    "    # Schrijf een placeholder of jouw eigen pipeline code naar dit pad\n",
    "    src_path.write_text(\n",
    "        \"# TODO: Voeg hier de code van deel2_pipeline.py toe\\n\"\n",
    "        \"def main():\\n\"\n",
    "        \"    print('Pipeline code ontbreekt. Voeg deze toe aan /mnt/data/deel2_pipeline.py')\\n\"\n",
    "        \"main()\\n\",\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "code = src_path.read_text(encoding=\"utf-8\")\n",
    "code = code.replace('DATA_PATH = \"college_statistics.csv\"', f'DATA_PATH = \"{DATA_PATH}\"')\n",
    "\n",
    "# 3) Schrijf naar een tijdelijke runner en voer uit\n",
    "runner_path = Path(\"/mnt/data/deel2_pipeline_run.py\")\n",
    "runner_path.write_text(code, encoding=\"utf-8\")\n",
    "\n",
    "# 4) Run (roept zelf main() aan)\n",
    "%run -i /mnt/data/deel2_pipeline_run.py\n",
    "\n",
    "print(\"\\n✅ Klaar. Bekijk de map ./outputs (figures/, tables/, reports/summary.txt).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66bfc9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/Library/Python/3.13/lib/python/site-packages/IPython/core/interactiveshell.py:3699\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[2]\u001b[39m\u001b[92m, line 366\u001b[39m\n    main()\n",
      "  Cell \u001b[92mIn[2]\u001b[39m\u001b[92m, line 258\u001b[39m in \u001b[95mmain\u001b[39m\n    model_apps = smf.ols(formula_apps, data=df_train).fit()\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/model.py:203\u001b[39m in \u001b[95mfrom_formula\u001b[39m\n    tmp = handle_formula_data(data, None, formula, depth=eval_env,\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/formula/formulatools.py:63\u001b[39m in \u001b[95mhandle_formula_data\u001b[39m\n    result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/patsy/highlevel.py:319\u001b[39m in \u001b[95mdmatrices\u001b[39m\n    (lhs, rhs) = _do_highlevel_design(\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/patsy/highlevel.py:164\u001b[39m in \u001b[95m_do_highlevel_design\u001b[39m\n    design_infos = _try_incr_builders(\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/patsy/highlevel.py:56\u001b[39m in \u001b[95m_try_incr_builders\u001b[39m\n    return design_matrix_builders(\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/patsy/build.py:743\u001b[39m in \u001b[95mdesign_matrix_builders\u001b[39m\n    factor_states = _factors_memorize(all_factors, data_iter_maker, eval_env)\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/patsy/build.py:393\u001b[39m in \u001b[95m_factors_memorize\u001b[39m\n    which_pass = factor.memorize_passes_needed(state, eval_env)\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/patsy/eval.py:504\u001b[39m in \u001b[95mmemorize_passes_needed\u001b[39m\n    subset_names = [name for name in ast_names(self.code) if name in env_namespace]\n",
      "  File \u001b[92m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/patsy/eval.py:111\u001b[39m in \u001b[95mast_names\u001b[39m\n    for node in ast.walk(ast.parse(code)):\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ast.py:50\u001b[39m\u001b[36m in \u001b[39m\u001b[35mparse\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn compile(source, filename, mode, flags,\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<unknown>:1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mC(Unnamed: 0)\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Deel 2 — Vragen 5a–5l: Generieke pipeline\n",
    "Wijzig alleen DATA_PATH hieronder. De script detecteert automatisch kolommen,\n",
    "bouwt modellen, voert diagnostiek uit, maakt grafieken en schrijft resultaten weg.\n",
    "\n",
    "Vereiste packages:\n",
    "  pip install pandas numpy scipy statsmodels scikit-learn matplotlib patsy\n",
    "\n",
    "Uitvoer:\n",
    "  ./outputs/\n",
    "    - figures/*.png\n",
    "    - tables/*.csv\n",
    "    - reports/summary.txt\n",
    "\"\"\"\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices, dmatrix\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, linear_reset\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.graphics.regressionplots import plot_ccpr_grid\n",
    "\n",
    "# -----------------------------\n",
    "# === CONFIG ===\n",
    "# -----------------------------\n",
    "DATA_PATH = \"college_statistics.csv\"      # <<<<< Verander ALLEEN dit pad\n",
    "TARGET = \"Apps\"                           # Doelvariabele\n",
    "SEED = 123                                # Reproduceerbaarheid\n",
    "N_TRAIN = 600                             # Grootte van estimation/train sample\n",
    "N_FOLDS = 5                               # Voor cross-validation\n",
    "\n",
    "# -----------------------------\n",
    "# === OUTPUT MAP ===\n",
    "# -----------------------------\n",
    "OUT_DIR = \"outputs\"\n",
    "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
    "TAB_DIR = os.path.join(OUT_DIR, \"tables\")\n",
    "REP_DIR = os.path.join(OUT_DIR, \"reports\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(TAB_DIR, exist_ok=True)\n",
    "os.makedirs(REP_DIR, exist_ok=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# -----------------------------\n",
    "# === HULPFUNCTIES ===\n",
    "# -----------------------------\n",
    "def safe_log(x: pd.Series, min_shift: float = 1e-6) -> pd.Series:\n",
    "    \"\"\"Log met kleine shift zodat 0/negatieven worden vermeden.\"\"\"\n",
    "    shift = max(min_shift, 1e-6)\n",
    "    if (x <= 0).any():\n",
    "        shift = max(shift, float(np.abs(x.min())) + 1e-6)\n",
    "    return np.log(x + shift)\n",
    "\n",
    "def duan_smearing_factor(residuals: np.ndarray) -> float:\n",
    "    \"\"\"Duan (1983) smearing factor voor terugtransformatie van log-model.\"\"\"\n",
    "    return float(np.mean(np.exp(residuals)))\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mae(y_true, y_pred) -> float:\n",
    "    return float(mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "def numeric_and_categorical_cols(df: pd.DataFrame, target: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Detecteer numerieke en categorische kolommen (exclusief target).\"\"\"\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if target in num_cols:\n",
    "        num_cols.remove(target)\n",
    "    cat_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "def build_formula(target: str, num_cols: List[str], cat_cols: List[str]) -> str:\n",
    "    \"\"\"Bouw een patsy-formule met automatische categorische encoding.\"\"\"\n",
    "    rhs_terms = []\n",
    "    rhs_terms += num_cols\n",
    "    rhs_terms += [f\"C({c})\" for c in cat_cols]\n",
    "    rhs = \" + \".join(rhs_terms) if rhs_terms else \"1\"\n",
    "    return f\"{target} ~ {rhs}\"\n",
    "\n",
    "def backward_elimination(formula: str, df: pd.DataFrame, p_thresh: float = 0.05) -> sm.regression.linear_model.RegressionResultsWrapper:\n",
    "    \"\"\"Backward elimination op basis van p-waarden.\"\"\"\n",
    "    current_formula = formula\n",
    "    while True:\n",
    "        model = smf.ols(current_formula, data=df).fit()\n",
    "        pvals = model.pvalues.drop(\"Intercept\", errors=\"ignore\")\n",
    "        if pvals.empty:\n",
    "            break\n",
    "        worst = pvals.idxmax()\n",
    "        worst_p = pvals.max()\n",
    "        if worst_p <= p_thresh:\n",
    "            break\n",
    "        # variabele verwijderen uit formule\n",
    "        terms = current_formula.split(\"~\")[1].strip().split(\"+\")\n",
    "        terms = [t.strip() for t in terms if t.strip() != worst]\n",
    "        new_rhs = \" + \".join(terms) if terms else \"1\"\n",
    "        current_formula = f\"{TARGET} ~ {new_rhs}\"\n",
    "    return smf.ols(current_formula, data=df).fit()\n",
    "\n",
    "def model_diagnostics(model, df: pd.DataFrame, target: str, prefix: str):\n",
    "    \"\"\"Voer diagnostiek uit (5e/5g) en schrijf plots + tabelletjes weg.\"\"\"\n",
    "    # Residuals en fitted\n",
    "    resid = model.resid\n",
    "    fitted = model.fittedvalues\n",
    "\n",
    "    # 1) Normaliteit residuen (Shapiro) + QQ plot\n",
    "    sh_p = stats.shapiro(resid).pvalue if len(resid) <= 5000 else np.nan\n",
    "    fig = qqplot(resid, line=\"45\")\n",
    "    plt.title(f\"QQ-plot residuen — {prefix}\")\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(FIG_DIR, f\"{prefix}_qq_residuals.png\")\n",
    "    plt.savefig(fig_path, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    # 2) Homoskedasticiteit (Breusch–Pagan)\n",
    "    exog = model.model.exog\n",
    "    bp_LM, bp_LMp, bp_F, bp_Fp = het_breuschpagan(resid, exog)\n",
    "\n",
    "    # 3) RESET (lineaire specificatie)\n",
    "    reset_p = linear_reset(model, power=2).pvalue\n",
    "\n",
    "    # 4) Autocorrelatie (Durbin–Watson)\n",
    "    dw = durbin_watson(resid)\n",
    "\n",
    "    diag = {\n",
    "        \"shapiro_p\": sh_p,\n",
    "        \"breusch_pagan_p\": bp_LMp,\n",
    "        \"reset_p\": reset_p,\n",
    "        \"durbin_watson\": dw,\n",
    "        \"aic\": model.aic,\n",
    "        \"bic\": model.bic,\n",
    "        \"r2\": model.rsquared,\n",
    "        \"adj_r2\": model.rsquared_adj,\n",
    "        \"n_params\": int(model.df_model) + 1\n",
    "    }\n",
    "    pd.DataFrame([diag]).to_csv(os.path.join(TAB_DIR, f\"{prefix}_diagnostics.csv\"), index=False)\n",
    "\n",
    "    # 5) CCPR-grid\n",
    "    try:\n",
    "        fig = plot_ccpr_grid(model)\n",
    "        plt.suptitle(f\"CCPR-plots — {prefix}\")\n",
    "        plt.tight_layout()\n",
    "        fig_path = os.path.join(FIG_DIR, f\"{prefix}_ccpr_grid.png\")\n",
    "        plt.savefig(fig_path, dpi=160)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        with open(os.path.join(REP_DIR, f\"{prefix}_ccpr_warning.txt\"), \"w\") as f:\n",
    "            f.write(str(e))\n",
    "\n",
    "def cv_scores_log_model(df_train: pd.DataFrame, formula_log: str, target: str, n_folds: int = 5, random_state: int = 123) -> Dict[str, float]:\n",
    "    \"\"\"5-fold CV voor log-model — rapporteer RMSE/MAE op log- én Apps-schaal (met Duan).\"\"\"\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    rmse_log, mae_log, rmse_apps, mae_apps = [], [], [], []\n",
    "\n",
    "    y_full = df_train[target].values\n",
    "    for tr_idx, va_idx in kf.split(df_train):\n",
    "        df_tr = df_train.iloc[tr_idx].copy()\n",
    "        df_va = df_train.iloc[va_idx].copy()\n",
    "\n",
    "        # Fit op log-schaal\n",
    "        m = smf.ols(formula_log, data=df_tr).fit()\n",
    "        # Duan smearing op train-residuen\n",
    "        smear = duan_smearing_factor(m.resid.values)\n",
    "\n",
    "        # Validatie-voorspellingen\n",
    "        log_pred = m.predict(df_va)\n",
    "        y_pred_apps = np.exp(log_pred) * smear\n",
    "        y_true_apps = df_va[target].values\n",
    "\n",
    "        rmse_log.append(rmse(np.log(y_true_apps + 1e-6), log_pred))\n",
    "        mae_log.append(mae(np.log(y_true_apps + 1e-6), log_pred))\n",
    "        rmse_apps.append(rmse(y_true_apps, y_pred_apps))\n",
    "        mae_apps.append(mae(y_true_apps, y_pred_apps))\n",
    "\n",
    "    return {\n",
    "        \"CV_RMSE_log_mean\": float(np.mean(rmse_log)),\n",
    "        \"CV_RMSE_log_sd\": float(np.std(rmse_log, ddof=1)),\n",
    "        \"CV_MAE_log_mean\": float(np.mean(mae_log)),\n",
    "        \"CV_MAE_log_sd\": float(np.std(mae_log, ddof=1)),\n",
    "        \"CV_RMSE_apps_mean\": float(np.mean(rmse_apps)),\n",
    "        \"CV_RMSE_apps_sd\": float(np.std(rmse_apps, ddof=1)),\n",
    "        \"CV_MAE_apps_mean\": float(np.mean(mae_apps)),\n",
    "        \"CV_MAE_apps_sd\": float(np.std(mae_apps, ddof=1)),\n",
    "    }\n",
    "\n",
    "def add_generic_transforms(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Voeg veilige, generieke transformaties/interacties toe als de kolommen bestaan (5i).\"\"\"\n",
    "    out = df.copy()\n",
    "    if \"Top10perc\" in out: out[\"Top10perc_sq\"] = out[\"Top10perc\"] ** 2\n",
    "    if \"Expend\" in out: out[\"log_Expend\"] = safe_log(out[\"Expend\"])\n",
    "    if {\"PhD\", \"Outstate\"}.issubset(out.columns):\n",
    "        out[\"PhD_Outstate\"] = out[\"PhD\"] * out[\"Outstate\"]\n",
    "    return out\n",
    "\n",
    "def print_and_write_summary(lines: List[str], path: str):\n",
    "    txt = \"\\n\".join(lines)\n",
    "    print(txt)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(txt)\n",
    "\n",
    "# -----------------------------\n",
    "# === MAIN PIPELINE ===\n",
    "# -----------------------------\n",
    "def main():\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    # 5a — Data laden en normaliteit van TARGET beoordelen\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    if TARGET not in df.columns:\n",
    "        raise ValueError(f\"TARGET '{TARGET}' niet gevonden in dataset. Kolommen: {list(df.columns)}\")\n",
    "\n",
    "    # Histogram en QQ-plot van TARGET\n",
    "    plt.figure()\n",
    "    plt.hist(df[TARGET].dropna(), bins=30)\n",
    "    plt.title(f\"Histogram — {TARGET}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, \"5a_hist_target.png\"), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    fig = qqplot(df[TARGET].dropna(), line=\"45\")\n",
    "    plt.title(f\"QQ-plot — {TARGET}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, \"5a_qq_target.png\"), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    shapiro_p = stats.shapiro(df[TARGET].dropna()).pvalue if len(df) <= 5000 else np.nan\n",
    "    pd.DataFrame([{\"shapiro_p_target\": shapiro_p}]).to_csv(os.path.join(TAB_DIR, \"5a_shapiro_target.csv\"), index=False)\n",
    "\n",
    "    # 5b — Split estimation/test (reproduceerbaar)\n",
    "    if len(df) < N_TRAIN + 1:\n",
    "        raise ValueError(f\"Te weinig observaties ({len(df)}). N_TRAIN={N_TRAIN} vereist.\")\n",
    "    df_train, df_test = train_test_split(df, train_size=N_TRAIN, random_state=SEED)\n",
    "    pd.DataFrame([{\"N_train\": len(df_train), \"N_test\": len(df_test)}]).to_csv(os.path.join(TAB_DIR, \"5b_split_sizes.csv\"), index=False)\n",
    "\n",
    "    # 5c — Basis lineair Apps-model (exclusief gevolgvariabelen Accept/Enroll indien aanwezig)\n",
    "    forbid = {\"Accept\", \"Enroll\"}\n",
    "    num_cols, cat_cols = numeric_and_categorical_cols(df_train, TARGET)\n",
    "    num_cols = [c for c in num_cols if c not in forbid]\n",
    "    cat_cols = [c for c in cat_cols if c not in forbid]\n",
    "    formula_apps = build_formula(TARGET, num_cols, cat_cols)\n",
    "    model_apps = smf.ols(formula_apps, data=df_train).fit()\n",
    "    model_apps.save(os.path.join(REP_DIR, \"5c_model_apps.pickle\"))\n",
    "    with open(os.path.join(REP_DIR, \"5c_model_apps.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model_apps.summary().as_text())\n",
    "\n",
    "    # 5d — Backward elimination op Apps-model\n",
    "    model_apps_be = backward_elimination(formula_apps, df_train, p_thresh=0.05)\n",
    "    with open(os.path.join(REP_DIR, \"5d_model_apps_backward.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model_apps_be.summary().as_text())\n",
    "    pd.DataFrame({\"final_formula\":[model_apps_be.model.formula]}).to_csv(os.path.join(TAB_DIR, \"5d_final_formula_apps.csv\"), index=False)\n",
    "\n",
    "    # 5e — Aannamencheck (Apps BE-model)\n",
    "    model_diagnostics(model_apps_be, df_train, TARGET, prefix=\"5e_apps_backward\")\n",
    "\n",
    "    # 5f — Log-transformatie TARGET\n",
    "    df_train_log = df_train.copy()\n",
    "    df_test_log = df_test.copy()\n",
    "    df_train_log[\"log_\" + TARGET] = safe_log(df_train[TARGET])\n",
    "    df_test_log[\"log_\" + TARGET]  = safe_log(df_test[TARGET])\n",
    "    # Formule voor log(TARGET) met dezelfde predictors\n",
    "    formula_log = model_apps_be.model.formula.replace(TARGET, \"log_\" + TARGET)\n",
    "    model_log = smf.ols(formula_log, data=df_train_log).fit()\n",
    "    with open(os.path.join(REP_DIR, \"5f_model_log.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model_log.summary().as_text())\n",
    "\n",
    "    # 5g — Aannamencheck (log-model)\n",
    "    model_diagnostics(model_log, df_train_log, \"log_\" + TARGET, prefix=\"5g_log_model\")\n",
    "\n",
    "    # 5h — Cross-Validation (log-model)\n",
    "    cv_res = cv_scores_log_model(df_train_log, formula_log, target=TARGET, n_folds=N_FOLDS, random_state=SEED)\n",
    "    pd.DataFrame([cv_res]).to_csv(os.path.join(TAB_DIR, \"5h_cv_log_model.csv\"), index=False)\n",
    "\n",
    "    # 5i — Transformaties & interacties en herfitten\n",
    "    df_train_t = add_generic_transforms(df_train_log)\n",
    "    df_test_t  = add_generic_transforms(df_test_log)\n",
    "\n",
    "    # Bouw formule opnieuw inclusief eventuele nieuwe kolommen (alle numeriek + categorisch zoals eerder)\n",
    "    num_cols_t, cat_cols_t = numeric_and_categorical_cols(df_train_t, TARGET)\n",
    "    num_cols_t = [c for c in num_cols_t if c not in forbid]\n",
    "    cat_cols_t = [c for c in cat_cols_t if c not in forbid]\n",
    "    # Gebruik log-target\n",
    "    formula_log_t = build_formula(\"log_\" + TARGET, num_cols_t, cat_cols_t)\n",
    "    model_log_t = smf.ols(formula_log_t, data=df_train_t).fit()\n",
    "    with open(os.path.join(REP_DIR, \"5i_model_log_transforms.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model_log_t.summary().as_text())\n",
    "\n",
    "    # Vergelijk kernstatistieken\n",
    "    comp = pd.DataFrame([\n",
    "        {\"Model\":\"Origineel log(Apps)\", \"Adj_R2\": model_log.rsquared_adj, \"AIC\": model_log.aic, \"BIC\": model_log.bic},\n",
    "        {\"Model\":\"Met transformaties\",  \"Adj_R2\": model_log_t.rsquared_adj, \"AIC\": model_log_t.aic, \"BIC\": model_log_t.bic},\n",
    "    ])\n",
    "    comp.to_csv(os.path.join(TAB_DIR, \"5i_model_compare.csv\"), index=False)\n",
    "\n",
    "    # Testprestatie op Apps-schaal (met Duan smearing)\n",
    "    smear = duan_smearing_factor(model_log.resid.values)\n",
    "    smear_t = duan_smearing_factor(model_log_t.resid.values)\n",
    "\n",
    "    log_pred_test = model_log.predict(df_test_t)\n",
    "    log_pred_test_t = model_log_t.predict(df_test_t)\n",
    "\n",
    "    pred_apps = np.exp(log_pred_test) * smear\n",
    "    pred_apps_t = np.exp(log_pred_test_t) * smear_t\n",
    "    rmse_test = rmse(df_test[TARGET].values, pred_apps)\n",
    "    rmse_test_t = rmse(df_test[TARGET].values, pred_apps_t)\n",
    "\n",
    "    pd.DataFrame([\n",
    "        {\"Model\":\"Origineel\", \"RMSE_test_apps\": rmse_test},\n",
    "        {\"Model\":\"Verbeterd\", \"RMSE_test_apps\": rmse_test_t},\n",
    "    ]).to_csv(os.path.join(TAB_DIR, \"5i_test_performance.csv\"), index=False)\n",
    "\n",
    "    # 5j — Belangrijkste predictoren (op basis van verbeterd log-model)\n",
    "    coefs = model_log_t.params.sort_values(key=np.abs, ascending=False)\n",
    "    top = coefs.head(12).rename(\"coef\").to_frame()\n",
    "    top.to_csv(os.path.join(TAB_DIR, \"5j_top_coefficients.csv\"))\n",
    "\n",
    "    # 5k — Voorspellingen & intervallen (train + test), log- en Apps-schaal\n",
    "    pred_train = model_log_t.get_prediction(df_train_t).summary_frame(alpha=0.05)  # mean_ci\n",
    "    pred_test  = model_log_t.get_prediction(df_test_t).summary_frame(alpha=0.05)\n",
    "\n",
    "    # Back-transform met smearing\n",
    "    for frame, name in [(pred_train, \"train\"), (pred_test, \"test\")]:\n",
    "        frame[\"pred_apps\"] = np.exp(frame[\"mean\"]) * smear_t\n",
    "        frame[\"ci_lo_apps\"] = np.exp(frame[\"mean_ci_lower\"]) * smear_t\n",
    "        frame[\"ci_hi_apps\"] = np.exp(frame[\"mean_ci_upper\"]) * smear_t\n",
    "        frame.to_csv(os.path.join(TAB_DIR, f\"5k_predictions_{name}.csv\"), index=True)\n",
    "\n",
    "    # Rapport: kernsamenvatting 5a–5l\n",
    "    lines = []\n",
    "    lines.append(\"=== Deel 2 — Samenvatting 5a–5l ===\")\n",
    "    lines.append(f\"Dataset: {DATA_PATH}, N={len(df)}; Train={len(df_train)}; Test={len(df_test)}; Seed={SEED}\")\n",
    "    lines.append(f\"5a Shapiro p (TARGET): {shapiro_p:.4g}\")\n",
    "    lines.append(f\"5c Formula (Apps): {formula_apps}\")\n",
    "    lines.append(f\"5d Final (Apps BE): {model_apps_be.model.formula}\")\n",
    "    lines.append(f\"5f Log Formula: {formula_log}\")\n",
    "    lines.append(f\"5i Log+Transforms Formula: {formula_log_t}\")\n",
    "    lines.append(\"---- Fit-statistieken ----\")\n",
    "    lines.append(f\"Apps BE: R2={model_apps_be.rsquared:.3f}, AdjR2={model_apps_be.rsquared_adj:.3f}, AIC={model_apps_be.aic:.1f}, BIC={model_apps_be.bic:.1f}\")\n",
    "    lines.append(f\"Log:     R2={model_log.rsquared:.3f},   AdjR2={model_log.rsquared_adj:.3f},   AIC={model_log.aic:.1f},   BIC={model_log.bic:.1f}\")\n",
    "    lines.append(f\"Log+T:   R2={model_log_t.rsquared:.3f}, AdjR2={model_log_t.rsquared_adj:.3f}, AIC={model_log_t.aic:.1f}, BIC={model_log_t.bic:.1f}\")\n",
    "    lines.append(\"---- 5h Cross-Validation (log-model) ----\")\n",
    "    lines.append(json.dumps(cv_res, indent=2))\n",
    "    lines.append(\"---- 5i Testprestatie (Apps-schaal, Duan) ----\")\n",
    "    lines.append(f\"Origineel log RMSE_test={rmse_test:.2f}\")\n",
    "    lines.append(f\"Verbeterd log RMSE_test={rmse_test_t:.2f}\")\n",
    "    print_and_write_summary(lines, os.path.join(REP_DIR, \"summary.txt\"))\n",
    "\n",
    "    print(\"\\nKlaar ✅  Bekijk de map ./outputs voor figuren, tabellen en rapporten.\")\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
